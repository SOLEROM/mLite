# lite-RT (TFLM)

* LiteRT (short for Lite Runtime), formerly known as TensorFlow Lite, is Google's high-performance runtime for on-device AI.
* Google rebranded TensorFlow Lite to LiteRT on September 4, 2024


## topics

* [flatBuffer](./flatBuffer.md)
* [inference](./inference.md)


## delegates
* [hwAccel](./hwAccel.md)
* [benchmark](./benchmark.md)


## micro
* [micro](./micro.md)
* [hello_world x86 sin example](./hello_world/readme.md)
* [new CPP](./new_cpp.md)


## py-tflite
* [pylite](pylite.md)



???  tflite-support 

## steps
* use [preTrainedModels](./preTrainedModels.md)
* convert a TensorFlow model to the LiteRT format 
    * [models_for_conversion](./models_for_conversion.md)
    * [convertions_tools](./convertions_tools.md)
* convert pytorch model to LiteRT format



## 

* [port to new platform](https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/docs/new_platform_support.md)